nohup: ignoring input
{'R': 54000,
 'alpha': 10.0,
 'batch_size': 256,
 'cq_lambda': 0.0,
 'dataset': 'cifar10',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/database.txt',
 'img_model': 'alexnet',
 'img_te': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/test.txt',
 'img_tr': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/train.txt',
 'label_dim': 10,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'cross_entropy',
 'max_iter': 2000,
 'model_weights': '../../DeepHash/architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 32,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../DeepHash/architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2019-05-04 21:15:24.259166 #train# start training
2019-05-04 21:15:38.688765 #train# step    1, loss = inf, cross_entropy loss = inf, 8.0 sec/batch
2019-05-04 21:15:40.153802 #train# step    2, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:41.537249 #train# step    3, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:42.977394 #train# step    4, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:44.374104 #train# step    5, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:45.806558 #train# step    6, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:47.196681 #train# step    7, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:48.629731 #train# step    8, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:50.054049 #train# step    9, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:51.504630 #train# step   10, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:52.905877 #train# step   11, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:54.341216 #train# step   12, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:55.741551 #train# step   13, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:15:57.218113 #train# step   14, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:15:58.624148 #train# step   15, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:00.062374 #train# step   16, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:01.475243 #train# step   17, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:02.914230 #train# step   18, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:04.325491 #train# step   19, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:05.690374 #train# step   20, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:07.066342 #train# step   21, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:08.440389 #train# step   22, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:09.786213 #train# step   23, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:11.154416 #train# step   24, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:12.526257 #train# step   25, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:14.010410 #train# step   26, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:15.547677 #train# step   27, loss = nan, cross_entropy loss = inf, 1.5 sec/batch
2019-05-04 21:16:17.059182 #train# step   28, loss = nan, cross_entropy loss = inf, 1.5 sec/batch
2019-05-04 21:16:18.517081 #train# step   29, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:19.960906 #train# step   30, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:21.420776 #train# step   31, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:22.850429 #train# step   32, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:24.339483 #train# step   33, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:25.771948 #train# step   34, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:27.230275 #train# step   35, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:28.691797 #train# step   36, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:30.145850 #train# step   37, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:31.613985 #train# step   38, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:33.001648 #train# step   39, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:34.490327 #train# step   40, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:35.848896 #train# step   41, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:37.393943 #train# step   42, loss = nan, cross_entropy loss = inf, 1.5 sec/batch
2019-05-04 21:16:38.812313 #train# step   43, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:40.249693 #train# step   44, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:41.641480 #train# step   45, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:43.108035 #train# step   46, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:44.515148 #train# step   47, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:45.956876 #train# step   48, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:47.342348 #train# step   49, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:48.763363 #train# step   50, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:50.148641 #train# step   51, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:51.547373 #train# step   52, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:52.912057 #train# step   53, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:55.234121 #train# step   54, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:16:56.622259 #train# step   55, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:58.023982 #train# step   56, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:16:59.444850 #train# step   57, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:00.817154 #train# step   58, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:02.202961 #train# step   59, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:03.606365 #train# step   60, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:04.973043 #train# step   61, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:06.361707 #train# step   62, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:07.710031 #train# step   63, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:09.124891 #train# step   64, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:10.478923 #train# step   65, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:11.846177 #train# step   66, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:13.219793 #train# step   67, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:14.623972 #train# step   68, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:16.002792 #train# step   69, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:17.402418 #train# step   70, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:18.778623 #train# step   71, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:20.229349 #train# step   72, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:21.583527 #train# step   73, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:23.017913 #train# step   74, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:24.420305 #train# step   75, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:25.872432 #train# step   76, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:27.213664 #train# step   77, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:28.639794 #train# step   78, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:30.081933 #train# step   79, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:31.535164 #train# step   80, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:32.892146 #train# step   81, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:34.352309 #train# step   82, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:35.814545 #train# step   83, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:37.268783 #train# step   84, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:38.685059 #train# step   85, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:40.132806 #train# step   86, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:41.553565 #train# step   87, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:42.971310 #train# step   88, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:44.401823 #train# step   89, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:45.735651 #train# step   90, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:47.141202 #train# step   91, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:48.580780 #train# step   92, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:50.065466 #train# step   93, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:51.443759 #train# step   94, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:52.832242 #train# step   95, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:54.226746 #train# step   96, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:55.594809 #train# step   97, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:57.031104 #train# step   98, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:17:58.400393 #train# step   99, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:17:59.762480 #train# step  100, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:01.155076 #train# step  101, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:02.551712 #train# step  102, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:03.978305 #train# step  103, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:05.425114 #train# step  104, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:06.779099 #train# step  105, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:08.195064 #train# step  106, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:09.651149 #train# step  107, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:11.091559 #train# step  108, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:12.490356 #train# step  109, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:13.919697 #train# step  110, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:15.342661 #train# step  111, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:16.718962 #train# step  112, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:18.088383 #train# step  113, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:19.443253 #train# step  114, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:20.789297 #train# step  115, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:22.152321 #train# step  116, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:23.541921 #train# step  117, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:25.003732 #train# step  118, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:26.425760 #train# step  119, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:27.807947 #train# step  120, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:29.166223 #train# step  121, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:30.548717 #train# step  122, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:32.037733 #train# step  123, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:33.466990 #train# step  124, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:34.804229 #train# step  125, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:36.170680 #train# step  126, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:37.515225 #train# step  127, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:38.870353 #train# step  128, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:40.217307 #train# step  129, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:41.567177 #train# step  130, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:42.912559 #train# step  131, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:44.270288 #train# step  132, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:45.613802 #train# step  133, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:47.002005 #train# step  134, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:48.475552 #train# step  135, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:49.903625 #train# step  136, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:18:51.250305 #train# step  137, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:52.618308 #train# step  138, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:53.960888 #train# step  139, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:55.326387 #train# step  140, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:56.665725 #train# step  141, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:58.039853 #train# step  142, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:18:59.394430 #train# step  143, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:00.765443 #train# step  144, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:02.107306 #train# step  145, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:03.457372 #train# step  146, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:04.807774 #train# step  147, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:06.221537 #train# step  148, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:07.608098 #train# step  149, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:09.037232 #train# step  150, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:10.385218 #train# step  151, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:11.801447 #train# step  152, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:13.197279 #train# step  153, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:14.592551 #train# step  154, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:15.910712 #train# step  155, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:17.332523 #train# step  156, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:18.727499 #train# step  157, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:20.146977 #train# step  158, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:21.469338 #train# step  159, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:22.829271 #train# step  160, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:24.185978 #train# step  161, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:25.565734 #train# step  162, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:26.958003 #train# step  163, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:28.374953 #train# step  164, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:29.803426 #train# step  165, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:31.162671 #train# step  166, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:32.502166 #train# step  167, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:33.867866 #train# step  168, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:35.266881 #train# step  169, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:36.692817 #train# step  170, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:38.129955 #train# step  171, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:19:39.523456 #train# step  172, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:40.870852 #train# step  173, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:42.224609 #train# step  174, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:43.561584 #train# step  175, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:44.948347 #train# step  176, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:46.299619 #train# step  177, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:47.658294 #train# step  178, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:49.003588 #train# step  179, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:50.360463 #train# step  180, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:51.746162 #train# step  181, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:53.145468 #train# step  182, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:54.495748 #train# step  183, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:55.854321 #train# step  184, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:57.173089 #train# step  185, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:58.506001 #train# step  186, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:19:59.871523 #train# step  187, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:01.265242 #train# step  188, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:02.626268 #train# step  189, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:03.986874 #train# step  190, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:05.403114 #train# step  191, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:20:06.762783 #train# step  192, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:08.102255 #train# step  193, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:09.438839 #train# step  194, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:10.785843 #train# step  195, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:12.146118 #train# step  196, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:13.493814 #train# step  197, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:14.851838 #train# step  198, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:16.213903 #train# step  199, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:17.598330 #train# step  200, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:18.944986 #train# step  201, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:20.296382 #train# step  202, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:21.619754 #train# step  203, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:23.015043 #train# step  204, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:24.355054 #train# step  205, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:25.687016 #train# step  206, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:26.989601 #train# step  207, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:28.337578 #train# step  208, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:29.681194 #train# step  209, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:31.020902 #train# step  210, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:32.345540 #train# step  211, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:33.674070 #train# step  212, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:34.993977 #train# step  213, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:36.338940 #train# step  214, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:37.667229 #train# step  215, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:39.021259 #train# step  216, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:40.354335 #train# step  217, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:41.708815 #train# step  218, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:43.068625 #train# step  219, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:44.444519 #train# step  220, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:45.783239 #train# step  221, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:47.123245 #train# step  222, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:48.473850 #train# step  223, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:49.867784 #train# step  224, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:51.217440 #train# step  225, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:52.574686 #train# step  226, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:53.908243 #train# step  227, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:55.261165 #train# step  228, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:56.597049 #train# step  229, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:57.959993 #train# step  230, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:20:59.322084 #train# step  231, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:00.687444 #train# step  232, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:02.027389 #train# step  233, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:03.379328 #train# step  234, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:04.727023 #train# step  235, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:06.120457 #train# step  236, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:07.511935 #train# step  237, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:08.909830 #train# step  238, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:10.262690 #train# step  239, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:11.623618 #train# step  240, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:12.958233 #train# step  241, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:14.366536 #train# step  242, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:15.765870 #train# step  243, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:17.169963 #train# step  244, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:18.492825 #train# step  245, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:19.840833 #train# step  246, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:21.175245 #train# step  247, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:22.520060 #train# step  248, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:23.841677 #train# step  249, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:25.175103 #train# step  250, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:26.502411 #train# step  251, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:27.845723 #train# step  252, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:29.226435 #train# step  253, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:30.619429 #train# step  254, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:32.020762 #train# step  255, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:33.379089 #train# step  256, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:34.708948 #train# step  257, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:36.059610 #train# step  258, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:37.418735 #train# step  259, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:38.781607 #train# step  260, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:40.159306 #train# step  261, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:41.571273 #train# step  262, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:42.908536 #train# step  263, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:44.256849 #train# step  264, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:45.553094 #train# step  265, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:21:46.899603 #train# step  266, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:48.220321 #train# step  267, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:49.562998 #train# step  268, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:50.888857 #train# step  269, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:52.291465 #train# step  270, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:53.683365 #train# step  271, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:55.136574 #train# step  272, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:21:56.483434 #train# step  273, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:57.825114 #train# step  274, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:21:59.151267 #train# step  275, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:00.503289 #train# step  276, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:01.843690 #train# step  277, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:03.165507 #train# step  278, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:04.499294 #train# step  279, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:05.834132 #train# step  280, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:07.162154 #train# step  281, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:08.501184 #train# step  282, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:09.827767 #train# step  283, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:11.171983 #train# step  284, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:12.502922 #train# step  285, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:13.832878 #train# step  286, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:15.149729 #train# step  287, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:16.480702 #train# step  288, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:17.799811 #train# step  289, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:19.118972 #train# step  290, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:20.441609 #train# step  291, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:21.772110 #train# step  292, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:23.080238 #train# step  293, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:24.424560 #train# step  294, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:25.750123 #train# step  295, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:27.091274 #train# step  296, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:28.418035 #train# step  297, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:29.747402 #train# step  298, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:31.063533 #train# step  299, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:32.406498 #train# step  300, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:33.726806 #train# step  301, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:35.054222 #train# step  302, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:36.371267 #train# step  303, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:37.696840 #train# step  304, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:39.008810 #train# step  305, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:40.310764 #train# step  306, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:41.614594 #train# step  307, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:42.922092 #train# step  308, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:44.233024 #train# step  309, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:45.562821 #train# step  310, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:46.860697 #train# step  311, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:48.186145 #train# step  312, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:49.493606 #train# step  313, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:50.819810 #train# step  314, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:52.131692 #train# step  315, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:53.451392 #train# step  316, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:54.741213 #train# step  317, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:56.067351 #train# step  318, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:57.378665 #train# step  319, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:22:58.703123 #train# step  320, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:00.012052 #train# step  321, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:01.338654 #train# step  322, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:02.663740 #train# step  323, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:03.990099 #train# step  324, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:05.343528 #train# step  325, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:06.704707 #train# step  326, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:08.064012 #train# step  327, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:09.471790 #train# step  328, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:23:10.803211 #train# step  329, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:12.147705 #train# step  330, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:13.487215 #train# step  331, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:14.825841 #train# step  332, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:16.164168 #train# step  333, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:17.501207 #train# step  334, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:18.833465 #train# step  335, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:20.168708 #train# step  336, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:21.497407 #train# step  337, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:22.840827 #train# step  338, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:24.165730 #train# step  339, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:25.502775 #train# step  340, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:26.831350 #train# step  341, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:28.174370 #train# step  342, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:29.496711 #train# step  343, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:30.826180 #train# step  344, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:32.143558 #train# step  345, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:33.487458 #train# step  346, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:34.817821 #train# step  347, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:36.133499 #train# step  348, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:37.451788 #train# step  349, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:38.772683 #train# step  350, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:40.095303 #train# step  351, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:41.410124 #train# step  352, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:42.718008 #train# step  353, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:44.041788 #train# step  354, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:45.358568 #train# step  355, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:46.686852 #train# step  356, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:47.979796 #train# step  357, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:49.310757 #train# step  358, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:50.627435 #train# step  359, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:51.948061 #train# step  360, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:53.263882 #train# step  361, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:54.589194 #train# step  362, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:55.902032 #train# step  363, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:57.198225 #train# step  364, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:23:58.472628 #train# step  365, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:23:59.804730 #train# step  366, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:01.107590 #train# step  367, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:02.438605 #train# step  368, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:03.713136 #train# step  369, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:24:05.041313 #train# step  370, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:06.347889 #train# step  371, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:07.670712 #train# step  372, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:09.013339 #train# step  373, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:10.359721 #train# step  374, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:11.700986 #train# step  375, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:13.124860 #train# step  376, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:24:14.473781 #train# step  377, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:15.813652 #train# step  378, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:17.141717 #train# step  379, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:18.474843 #train# step  380, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:19.793066 #train# step  381, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:21.121700 #train# step  382, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:22.455205 #train# step  383, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:23.780297 #train# step  384, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:25.108362 #train# step  385, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:26.456361 #train# step  386, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:27.795363 #train# step  387, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:29.134514 #train# step  388, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:30.463708 #train# step  389, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:31.802405 #train# step  390, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:33.136263 #train# step  391, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:34.474484 #train# step  392, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:35.811301 #train# step  393, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:37.130426 #train# step  394, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:38.446156 #train# step  395, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:39.777554 #train# step  396, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:41.085780 #train# step  397, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:42.466241 #train# step  398, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:43.807919 #train# step  399, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:45.147136 #train# step  400, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:46.483383 #train# step  401, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:47.811396 #train# step  402, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:49.120266 #train# step  403, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:50.445036 #train# step  404, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:51.760854 #train# step  405, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:53.098659 #train# step  406, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:54.415341 #train# step  407, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:55.749407 #train# step  408, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:57.070273 #train# step  409, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:58.396113 #train# step  410, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:24:59.695273 #train# step  411, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:01.027293 #train# step  412, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:02.333511 #train# step  413, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:03.660476 #train# step  414, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:04.968754 #train# step  415, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:06.301400 #train# step  416, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:07.620248 #train# step  417, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:09.000560 #train# step  418, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:10.375964 #train# step  419, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:11.763129 #train# step  420, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:13.073612 #train# step  421, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:14.416891 #train# step  422, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:15.815985 #train# step  423, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:17.260698 #train# step  424, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:25:18.598585 #train# step  425, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:19.937153 #train# step  426, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:21.280186 #train# step  427, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:22.651332 #train# step  428, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:24.052465 #train# step  429, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:25.471822 #train# step  430, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:25:26.809241 #train# step  431, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:28.167070 #train# step  432, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:29.503687 #train# step  433, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:30.846652 #train# step  434, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:32.185214 #train# step  435, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:33.545229 #train# step  436, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:34.880512 #train# step  437, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:36.207268 #train# step  438, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:37.541947 #train# step  439, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:38.878593 #train# step  440, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:40.206504 #train# step  441, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:41.566049 #train# step  442, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:43.022614 #train# step  443, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:25:44.440942 #train# step  444, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:25:45.770296 #train# step  445, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:47.109430 #train# step  446, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:48.405624 #train# step  447, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:25:49.753187 #train# step  448, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:51.157860 #train# step  449, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:25:52.554001 #train# step  450, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:53.891195 #train# step  451, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:55.228968 #train# step  452, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:56.562921 #train# step  453, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:57.938850 #train# step  454, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:25:59.355172 #train# step  455, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:00.770231 #train# step  456, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:02.113040 #train# step  457, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:03.455579 #train# step  458, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:04.778525 #train# step  459, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:06.140717 #train# step  460, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:07.530701 #train# step  461, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:08.946644 #train# step  462, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:10.287725 #train# step  463, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:11.633321 #train# step  464, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:12.978055 #train# step  465, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:14.345711 #train# step  466, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:15.753071 #train# step  467, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:17.170742 #train# step  468, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:18.520138 #train# step  469, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:19.862670 #train# step  470, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:21.192033 #train# step  471, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:22.535730 #train# step  472, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:23.933915 #train# step  473, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:25.276848 #train# step  474, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:26.664744 #train# step  475, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:27.980846 #train# step  476, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:29.315094 #train# step  477, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:30.641973 #train# step  478, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:32.020259 #train# step  479, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:33.420699 #train# step  480, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:34.879737 #train# step  481, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:36.224914 #train# step  482, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:37.526236 #train# step  483, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:38.863855 #train# step  484, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:40.180550 #train# step  485, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:41.566029 #train# step  486, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:42.979661 #train# step  487, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:44.404222 #train# step  488, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:26:45.740240 #train# step  489, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:47.077196 #train# step  490, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:48.408888 #train# step  491, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:49.725186 #train# step  492, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:51.044137 #train# step  493, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:52.365749 #train# step  494, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:53.687557 #train# step  495, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:55.018997 #train# step  496, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:56.364508 #train# step  497, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:57.703710 #train# step  498, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:26:59.038707 #train# step  499, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:00.394407 #train# step  500, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:01.731999 #train# step  501, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:03.060284 #train# step  502, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:04.375111 #train# step  503, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:05.692653 #train# step  504, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:07.081735 #train# step  505, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:08.521881 #train# step  506, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:27:09.838410 #train# step  507, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:11.171580 #train# step  508, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:12.501267 #train# step  509, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:13.850455 #train# step  510, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:15.237511 #train# step  511, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:16.606238 #train# step  512, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:17.984558 #train# step  513, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:19.303581 #train# step  514, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:20.624500 #train# step  515, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:21.942943 #train# step  516, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:23.269270 #train# step  517, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:24.594734 #train# step  518, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:25.923610 #train# step  519, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:27.253047 #train# step  520, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:28.591453 #train# step  521, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:29.938879 #train# step  522, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:31.300001 #train# step  523, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:32.640955 #train# step  524, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:33.965321 #train# step  525, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:35.379905 #train# step  526, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:27:36.712829 #train# step  527, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:38.045081 #train# step  528, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:39.370614 #train# step  529, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:40.698510 #train# step  530, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:41.994005 #train# step  531, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:27:43.358114 #train# step  532, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:44.694053 #train# step  533, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:46.043794 #train# step  534, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:47.391489 #train# step  535, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:48.725773 #train# step  536, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:50.051485 #train# step  537, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:51.385307 #train# step  538, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:52.719095 #train# step  539, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:54.066462 #train# step  540, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:55.415681 #train# step  541, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:56.742350 #train# step  542, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:58.082610 #train# step  543, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:27:59.413571 #train# step  544, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:00.747171 #train# step  545, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:02.068070 #train# step  546, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:03.388295 #train# step  547, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:04.718715 #train# step  548, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:06.046917 #train# step  549, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:07.379075 #train# step  550, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:08.714133 #train# step  551, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:10.028941 #train# step  552, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:11.343060 #train# step  553, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:12.655000 #train# step  554, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:13.974478 #train# step  555, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:15.288485 #train# step  556, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:16.597512 #train# step  557, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:17.909756 #train# step  558, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:19.238430 #train# step  559, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:20.561418 #train# step  560, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:21.886463 #train# step  561, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:23.219022 #train# step  562, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:24.538808 #train# step  563, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:25.867129 #train# step  564, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:27.191562 #train# step  565, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:28.510017 #train# step  566, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:29.833109 #train# step  567, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:31.161590 #train# step  568, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:32.491053 #train# step  569, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:33.821111 #train# step  570, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:35.141419 #train# step  571, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:36.471325 #train# step  572, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:37.810891 #train# step  573, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:39.219242 #train# step  574, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:28:40.538251 #train# step  575, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:41.873737 #train# step  576, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:43.196297 #train# step  577, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:44.517035 #train# step  578, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:45.837507 #train# step  579, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:47.162280 #train# step  580, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:48.479484 #train# step  581, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:49.801265 #train# step  582, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:51.125547 #train# step  583, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:52.448577 #train# step  584, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:53.777221 #train# step  585, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:55.099643 #train# step  586, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:56.417310 #train# step  587, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:57.746720 #train# step  588, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:28:59.050085 #train# step  589, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:00.341636 #train# step  590, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:01.655743 #train# step  591, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:02.962037 #train# step  592, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:04.271361 #train# step  593, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:05.577504 #train# step  594, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:06.882281 #train# step  595, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:08.201818 #train# step  596, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:09.513926 #train# step  597, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:10.819470 #train# step  598, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:12.128055 #train# step  599, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:13.442263 #train# step  600, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:14.756317 #train# step  601, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:16.062272 #train# step  602, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:17.369782 #train# step  603, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:18.673637 #train# step  604, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:19.985152 #train# step  605, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:21.303985 #train# step  606, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:22.621869 #train# step  607, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:23.936319 #train# step  608, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:25.239868 #train# step  609, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:26.546660 #train# step  610, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:27.859647 #train# step  611, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:29.178468 #train# step  612, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:30.496525 #train# step  613, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:31.812953 #train# step  614, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:33.132175 #train# step  615, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:34.450158 #train# step  616, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:35.765090 #train# step  617, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:37.078762 #train# step  618, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:38.390880 #train# step  619, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:39.707723 #train# step  620, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:41.017643 #train# step  621, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:42.326123 #train# step  622, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:43.631423 #train# step  623, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:44.946415 #train# step  624, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:46.261376 #train# step  625, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:47.565333 #train# step  626, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:48.878248 #train# step  627, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:50.187626 #train# step  628, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:51.520252 #train# step  629, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:52.842125 #train# step  630, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:54.159143 #train# step  631, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:55.486980 #train# step  632, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:56.802159 #train# step  633, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:58.120534 #train# step  634, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:29:59.435630 #train# step  635, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:00.748083 #train# step  636, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:02.083066 #train# step  637, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:03.404963 #train# step  638, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:04.727647 #train# step  639, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:06.049937 #train# step  640, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:07.373146 #train# step  641, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:08.696507 #train# step  642, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:10.021820 #train# step  643, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:11.342410 #train# step  644, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:12.670275 #train# step  645, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:13.995344 #train# step  646, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:15.340750 #train# step  647, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:16.681497 #train# step  648, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:18.024913 #train# step  649, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:19.416731 #train# step  650, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:20.799584 #train# step  651, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:22.164088 #train# step  652, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:23.515151 #train# step  653, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:24.864948 #train# step  654, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:26.219134 #train# step  655, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:27.577168 #train# step  656, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:28.914258 #train# step  657, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:30.263216 #train# step  658, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:31.622898 #train# step  659, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:32.970636 #train# step  660, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:34.334958 #train# step  661, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:35.699696 #train# step  662, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:37.047417 #train# step  663, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:38.414654 #train# step  664, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:39.787448 #train# step  665, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:41.144147 #train# step  666, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:42.489410 #train# step  667, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:43.840554 #train# step  668, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:45.209149 #train# step  669, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:46.591578 #train# step  670, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:47.931317 #train# step  671, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:49.267799 #train# step  672, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:50.585554 #train# step  673, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:51.909548 #train# step  674, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:53.234871 #train# step  675, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:54.562060 #train# step  676, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:55.866239 #train# step  677, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:57.185246 #train# step  678, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:58.499940 #train# step  679, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:30:59.821680 #train# step  680, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:01.138244 #train# step  681, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:02.456841 #train# step  682, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:03.772959 #train# step  683, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:05.100351 #train# step  684, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:06.408834 #train# step  685, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:07.716398 #train# step  686, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:09.032630 #train# step  687, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:10.338650 #train# step  688, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:11.706659 #train# step  689, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:13.075626 #train# step  690, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:14.468629 #train# step  691, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:15.793214 #train# step  692, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:17.130903 #train# step  693, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:18.534316 #train# step  694, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:31:19.887327 #train# step  695, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:21.285017 #train# step  696, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:22.638601 #train# step  697, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:23.962094 #train# step  698, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:25.282838 #train# step  699, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:26.605309 #train# step  700, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:27.929323 #train# step  701, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:29.272895 #train# step  702, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:30.631068 #train# step  703, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:31.973711 #train# step  704, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:33.312088 #train# step  705, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:34.630982 #train# step  706, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:36.063284 #train# step  707, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:31:37.425017 #train# step  708, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:38.752951 #train# step  709, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:40.071210 #train# step  710, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:41.397187 #train# step  711, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:42.731637 #train# step  712, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:44.048855 #train# step  713, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:45.391789 #train# step  714, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:46.723212 #train# step  715, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:48.080444 #train# step  716, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:49.419836 #train# step  717, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:50.760199 #train# step  718, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:52.090736 #train# step  719, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:53.424736 #train# step  720, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:54.747559 #train# step  721, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:56.078995 #train# step  722, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:57.407345 #train# step  723, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:31:58.786284 #train# step  724, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:00.088282 #train# step  725, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:01.427139 #train# step  726, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:02.760190 #train# step  727, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:04.077853 #train# step  728, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:05.386579 #train# step  729, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:06.702792 #train# step  730, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:08.026020 #train# step  731, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:09.348272 #train# step  732, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:10.670724 #train# step  733, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:12.007318 #train# step  734, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:13.343298 #train# step  735, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:14.685809 #train# step  736, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:16.015190 #train# step  737, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:17.343236 #train# step  738, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:18.644083 #train# step  739, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:19.974966 #train# step  740, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:21.295280 #train# step  741, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:22.606748 #train# step  742, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:23.919869 #train# step  743, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:25.260058 #train# step  744, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:26.579615 #train# step  745, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:27.898969 #train# step  746, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:29.226618 #train# step  747, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:30.557817 #train# step  748, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:31.875071 #train# step  749, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:33.198626 #train# step  750, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:34.511152 #train# step  751, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:35.832256 #train# step  752, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:37.166388 #train# step  753, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:38.486896 #train# step  754, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:39.811232 #train# step  755, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:41.137189 #train# step  756, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:42.458164 #train# step  757, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:43.791754 #train# step  758, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:45.123664 #train# step  759, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:46.476061 #train# step  760, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:47.825356 #train# step  761, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:49.159620 #train# step  762, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:50.530299 #train# step  763, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:51.863287 #train# step  764, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:53.190190 #train# step  765, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:54.513704 #train# step  766, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:55.840721 #train# step  767, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:57.165082 #train# step  768, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:58.486608 #train# step  769, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:32:59.808455 #train# step  770, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:01.128992 #train# step  771, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:02.458381 #train# step  772, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:03.785392 #train# step  773, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:05.103693 #train# step  774, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:06.421984 #train# step  775, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:07.746200 #train# step  776, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:09.067762 #train# step  777, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:10.395197 #train# step  778, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:11.713208 #train# step  779, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:13.027322 #train# step  780, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:14.340988 #train# step  781, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:15.653194 #train# step  782, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:16.973030 #train# step  783, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:18.284362 #train# step  784, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:19.593842 #train# step  785, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:20.903520 #train# step  786, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:22.219513 #train# step  787, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:23.528251 #train# step  788, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:24.846380 #train# step  789, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:26.155965 #train# step  790, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:27.468270 #train# step  791, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:28.785266 #train# step  792, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:30.101808 #train# step  793, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:31.419314 #train# step  794, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:32.724621 #train# step  795, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:34.034647 #train# step  796, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:35.344336 #train# step  797, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:36.668575 #train# step  798, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:38.001657 #train# step  799, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:39.309993 #train# step  800, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:40.626150 #train# step  801, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:41.940896 #train# step  802, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:43.255178 #train# step  803, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:44.554400 #train# step  804, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:45.865128 #train# step  805, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:47.165602 #train# step  806, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:48.481254 #train# step  807, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:49.794140 #train# step  808, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:51.112752 #train# step  809, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:52.423506 #train# step  810, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:53.751980 #train# step  811, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:55.065284 #train# step  812, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:56.386697 #train# step  813, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:57.703274 #train# step  814, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:33:59.017351 #train# step  815, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:00.349517 #train# step  816, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:01.658947 #train# step  817, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:02.984052 #train# step  818, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:04.325130 #train# step  819, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:05.640037 #train# step  820, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:06.956926 #train# step  821, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:08.269552 #train# step  822, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:09.594995 #train# step  823, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:10.916190 #train# step  824, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:12.229621 #train# step  825, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:13.558713 #train# step  826, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:14.868894 #train# step  827, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:16.190581 #train# step  828, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:17.511626 #train# step  829, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:18.832685 #train# step  830, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:20.163201 #train# step  831, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:21.481702 #train# step  832, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:22.810422 #train# step  833, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:24.126120 #train# step  834, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:25.488951 #train# step  835, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:26.811632 #train# step  836, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:28.140510 #train# step  837, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:29.466850 #train# step  838, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:30.790915 #train# step  839, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:32.116780 #train# step  840, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:33.488482 #train# step  841, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:34.811661 #train# step  842, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:36.165398 #train# step  843, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:37.483602 #train# step  844, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:38.825684 #train# step  845, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:40.158054 #train# step  846, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:41.477545 #train# step  847, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:42.801587 #train# step  848, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:44.125086 #train# step  849, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:45.452317 #train# step  850, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:46.779764 #train# step  851, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:48.103173 #train# step  852, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:49.428566 #train# step  853, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:50.758529 #train# step  854, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:52.084633 #train# step  855, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:53.406776 #train# step  856, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:54.719125 #train# step  857, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:56.032122 #train# step  858, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:57.346245 #train# step  859, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:34:58.664056 #train# step  860, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:00.080295 #train# step  861, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:35:01.382005 #train# step  862, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:02.706681 #train# step  863, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:04.013976 #train# step  864, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:05.325514 #train# step  865, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:06.629869 #train# step  866, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:07.944969 #train# step  867, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:09.257454 #train# step  868, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:10.575515 #train# step  869, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:11.853565 #train# step  870, loss = nan, cross_entropy loss = inf, 1.2 sec/batch
2019-05-04 21:35:13.156874 #train# step  871, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:14.468394 #train# step  872, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:15.776886 #train# step  873, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:17.090199 #train# step  874, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:18.384780 #train# step  875, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:19.690031 #train# step  876, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:21.007195 #train# step  877, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:22.315048 #train# step  878, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:23.626512 #train# step  879, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:24.928361 #train# step  880, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:26.242087 #train# step  881, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:27.526954 #train# step  882, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:28.846206 #train# step  883, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:30.161577 #train# step  884, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:31.487690 #train# step  885, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:32.798265 #train# step  886, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:34.118707 #train# step  887, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:35.435348 #train# step  888, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:36.751180 #train# step  889, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:38.067258 #train# step  890, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:39.380810 #train# step  891, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:40.681010 #train# step  892, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:41.994247 #train# step  893, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:43.310008 #train# step  894, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:44.630607 #train# step  895, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:45.983048 #train# step  896, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:47.391254 #train# step  897, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:35:48.796391 #train# step  898, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:35:50.106417 #train# step  899, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:51.417575 #train# step  900, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:52.726461 #train# step  901, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:54.054087 #train# step  902, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:55.387340 #train# step  903, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:56.709182 #train# step  904, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:58.016238 #train# step  905, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:35:59.353669 #train# step  906, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:00.697536 #train# step  907, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:02.025518 #train# step  908, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:03.364433 #train# step  909, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:04.693232 #train# step  910, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:06.029805 #train# step  911, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:07.361311 #train# step  912, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:08.677751 #train# step  913, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:09.986160 #train# step  914, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:11.305644 #train# step  915, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:12.610026 #train# step  916, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:13.930510 #train# step  917, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:15.247774 #train# step  918, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:16.547167 #train# step  919, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:17.861587 #train# step  920, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:19.178989 #train# step  921, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:20.493730 #train# step  922, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:21.818890 #train# step  923, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:23.138078 #train# step  924, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:24.453588 #train# step  925, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:25.771029 #train# step  926, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:27.097018 #train# step  927, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:28.410813 #train# step  928, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:29.736605 #train# step  929, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:31.055069 #train# step  930, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:32.374982 #train# step  931, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:33.690242 #train# step  932, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:35.002725 #train# step  933, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:36.314275 #train# step  934, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:37.628104 #train# step  935, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:38.938814 #train# step  936, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:40.257779 #train# step  937, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:41.570419 #train# step  938, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:42.890131 #train# step  939, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:44.207283 #train# step  940, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:45.577769 #train# step  941, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:46.940478 #train# step  942, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:48.307501 #train# step  943, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:49.690790 #train# step  944, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:51.022980 #train# step  945, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:52.354189 #train# step  946, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:53.696583 #train# step  947, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:55.037147 #train# step  948, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:56.367519 #train# step  949, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:57.700275 #train# step  950, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:36:59.043637 #train# step  951, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:00.394285 #train# step  952, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:01.743507 #train# step  953, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:03.103714 #train# step  954, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:04.477519 #train# step  955, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:05.819293 #train# step  956, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:07.126597 #train# step  957, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:08.465983 #train# step  958, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:09.799107 #train# step  959, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:11.127732 #train# step  960, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:12.461664 #train# step  961, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:13.792666 #train# step  962, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:15.141144 #train# step  963, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:16.475550 #train# step  964, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:17.795524 #train# step  965, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:19.122799 #train# step  966, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:20.440255 #train# step  967, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:21.779644 #train# step  968, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:23.117733 #train# step  969, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:24.439131 #train# step  970, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:25.757141 #train# step  971, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:27.065743 #train# step  972, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:28.371500 #train# step  973, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:29.696380 #train# step  974, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:31.023961 #train# step  975, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:32.347678 #train# step  976, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:33.670829 #train# step  977, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:34.983457 #train# step  978, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:36.313869 #train# step  979, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:37.637006 #train# step  980, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:38.949666 #train# step  981, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:40.285674 #train# step  982, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:41.636629 #train# step  983, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:42.968960 #train# step  984, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:44.267675 #train# step  985, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:45.597581 #train# step  986, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:46.934033 #train# step  987, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:48.262706 #train# step  988, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:49.612474 #train# step  989, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:50.960716 #train# step  990, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:52.297319 #train# step  991, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:53.638307 #train# step  992, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:54.962362 #train# step  993, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:56.285721 #train# step  994, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:57.615676 #train# step  995, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:37:58.939081 #train# step  996, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:00.270052 #train# step  997, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:01.605769 #train# step  998, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:02.938449 #train# step  999, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:04.270615 #train# step 1000, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:05.597040 #train# step 1001, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:06.930404 #train# step 1002, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:08.258676 #train# step 1003, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:09.586977 #train# step 1004, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:10.916888 #train# step 1005, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:12.243318 #train# step 1006, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:13.578370 #train# step 1007, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:14.899872 #train# step 1008, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:16.222434 #train# step 1009, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:17.545057 #train# step 1010, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:18.857035 #train# step 1011, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:20.175536 #train# step 1012, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:21.498888 #train# step 1013, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:22.819696 #train# step 1014, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:24.143803 #train# step 1015, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:25.457608 #train# step 1016, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:26.776439 #train# step 1017, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:28.097620 #train# step 1018, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:29.420025 #train# step 1019, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:30.743623 #train# step 1020, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:32.064734 #train# step 1021, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:33.395649 #train# step 1022, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:34.725806 #train# step 1023, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:36.038142 #train# step 1024, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:37.348280 #train# step 1025, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:38.682246 #train# step 1026, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:39.994360 #train# step 1027, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:41.329748 #train# step 1028, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:42.658201 #train# step 1029, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:43.987818 #train# step 1030, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:45.326788 #train# step 1031, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:46.646457 #train# step 1032, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:47.972325 #train# step 1033, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:49.270667 #train# step 1034, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:50.603721 #train# step 1035, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:51.940629 #train# step 1036, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:53.283291 #train# step 1037, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:54.620998 #train# step 1038, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:55.970192 #train# step 1039, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:57.327701 #train# step 1040, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:58.666480 #train# step 1041, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:38:59.990301 #train# step 1042, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:01.333342 #train# step 1043, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:02.687124 #train# step 1044, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:04.005260 #train# step 1045, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:05.331757 #train# step 1046, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:06.664082 #train# step 1047, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:07.972521 #train# step 1048, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:09.285336 #train# step 1049, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:10.612040 #train# step 1050, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:11.929353 #train# step 1051, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:13.259707 #train# step 1052, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:14.593788 #train# step 1053, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:15.922658 #train# step 1054, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:17.258196 #train# step 1055, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:18.587845 #train# step 1056, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:19.917010 #train# step 1057, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:21.242939 #train# step 1058, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:22.572926 #train# step 1059, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:23.902112 #train# step 1060, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:25.232315 #train# step 1061, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:26.565434 #train# step 1062, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:27.895760 #train# step 1063, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:29.202884 #train# step 1064, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:30.511989 #train# step 1065, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:31.810166 #train# step 1066, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:33.129805 #train# step 1067, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:34.458225 #train# step 1068, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:35.777732 #train# step 1069, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:37.099456 #train# step 1070, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:38.425590 #train# step 1071, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:39.748061 #train# step 1072, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:41.070952 #train# step 1073, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:42.396909 #train# step 1074, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:43.724602 #train# step 1075, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:45.054560 #train# step 1076, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:46.394832 #train# step 1077, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:47.719275 #train# step 1078, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:49.046986 #train# step 1079, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:50.375393 #train# step 1080, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:51.702640 #train# step 1081, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:53.028147 #train# step 1082, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:54.359445 #train# step 1083, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:55.689441 #train# step 1084, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:56.991411 #train# step 1085, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:58.322040 #train# step 1086, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:39:59.644150 #train# step 1087, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:00.956500 #train# step 1088, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:02.275461 #train# step 1089, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:03.571241 #train# step 1090, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:04.888948 #train# step 1091, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:06.214286 #train# step 1092, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:07.531199 #train# step 1093, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:08.872805 #train# step 1094, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:10.197283 #train# step 1095, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:11.525181 #train# step 1096, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:12.857571 #train# step 1097, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:14.186926 #train# step 1098, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:15.522023 #train# step 1099, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:16.854374 #train# step 1100, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:18.183164 #train# step 1101, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:19.496612 #train# step 1102, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:20.820781 #train# step 1103, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:22.151256 #train# step 1104, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:23.472560 #train# step 1105, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:24.810515 #train# step 1106, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:26.149001 #train# step 1107, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:27.487790 #train# step 1108, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:28.822728 #train# step 1109, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:30.159148 #train# step 1110, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:31.504232 #train# step 1111, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:32.853985 #train# step 1112, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:34.201625 #train# step 1113, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:35.549287 #train# step 1114, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:36.873735 #train# step 1115, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:38.195366 #train# step 1116, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:39.543753 #train# step 1117, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:40.883251 #train# step 1118, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:42.234154 #train# step 1119, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:43.571474 #train# step 1120, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:44.921247 #train# step 1121, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:46.246836 #train# step 1122, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:47.581116 #train# step 1123, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:48.929076 #train# step 1124, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:50.263640 #train# step 1125, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:51.596400 #train# step 1126, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:52.929210 #train# step 1127, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:54.262429 #train# step 1128, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:55.597949 #train# step 1129, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:56.925904 #train# step 1130, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:58.252513 #train# step 1131, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:40:59.590621 #train# step 1132, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:00.921744 #train# step 1133, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:02.256765 #train# step 1134, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:03.585099 #train# step 1135, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:04.912307 #train# step 1136, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:06.255969 #train# step 1137, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:07.588030 #train# step 1138, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:08.930219 #train# step 1139, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:10.263229 #train# step 1140, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:11.589609 #train# step 1141, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:12.916754 #train# step 1142, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:14.241423 #train# step 1143, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:15.567691 #train# step 1144, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:16.890258 #train# step 1145, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:18.216752 #train# step 1146, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:19.549418 #train# step 1147, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:20.856776 #train# step 1148, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:22.186272 #train# step 1149, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:23.515030 #train# step 1150, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:24.846132 #train# step 1151, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:26.180976 #train# step 1152, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:27.527040 #train# step 1153, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:28.862352 #train# step 1154, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:30.206480 #train# step 1155, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:31.532429 #train# step 1156, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:32.867038 #train# step 1157, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:34.194369 #train# step 1158, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:35.523265 #train# step 1159, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:36.850645 #train# step 1160, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:38.186195 #train# step 1161, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:39.514309 #train# step 1162, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:40.846059 #train# step 1163, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:42.175080 #train# step 1164, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:43.501644 #train# step 1165, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:44.848640 #train# step 1166, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:46.183180 #train# step 1167, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:47.505829 #train# step 1168, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:48.836522 #train# step 1169, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:50.165923 #train# step 1170, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:51.509353 #train# step 1171, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:52.845594 #train# step 1172, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:54.173738 #train# step 1173, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:55.504490 #train# step 1174, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:56.823037 #train# step 1175, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:58.139509 #train# step 1176, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:41:59.478351 #train# step 1177, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:00.812908 #train# step 1178, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:02.155923 #train# step 1179, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:03.478887 #train# step 1180, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:04.800054 #train# step 1181, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:06.343141 #train# step 1182, loss = nan, cross_entropy loss = inf, 1.5 sec/batch
2019-05-04 21:42:07.671050 #train# step 1183, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:09.008525 #train# step 1184, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:10.339152 #train# step 1185, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:11.664126 #train# step 1186, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:12.991403 #train# step 1187, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:14.318622 #train# step 1188, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:15.650304 #train# step 1189, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:16.985924 #train# step 1190, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:18.317738 #train# step 1191, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:19.653125 #train# step 1192, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:20.991585 #train# step 1193, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:22.327303 #train# step 1194, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:23.643037 #train# step 1195, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:24.975938 #train# step 1196, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:26.335344 #train# step 1197, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:27.678149 #train# step 1198, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:29.081056 #train# step 1199, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:42:30.416736 #train# step 1200, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:31.762989 #train# step 1201, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:33.096052 #train# step 1202, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:34.434246 #train# step 1203, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:35.765236 #train# step 1204, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:37.104171 #train# step 1205, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:38.501064 #train# step 1206, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:42:39.885396 #train# step 1207, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:41.338279 #train# step 1208, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:42:42.713779 #train# step 1209, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:44.060568 #train# step 1210, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:45.405690 #train# step 1211, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:46.746166 #train# step 1212, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:48.098655 #train# step 1213, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:49.436320 #train# step 1214, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:50.781116 #train# step 1215, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:52.131417 #train# step 1216, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:53.481806 #train# step 1217, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:54.818272 #train# step 1218, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:56.155313 #train# step 1219, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:57.489643 #train# step 1220, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:42:58.806413 #train# step 1221, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:00.122853 #train# step 1222, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:01.460734 #train# step 1223, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:02.796515 #train# step 1224, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:04.144709 #train# step 1225, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:05.489589 #train# step 1226, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:06.833774 #train# step 1227, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:08.188269 #train# step 1228, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:09.534280 #train# step 1229, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:10.875644 #train# step 1230, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:12.215013 #train# step 1231, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:13.547170 #train# step 1232, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:14.887278 #train# step 1233, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:16.226206 #train# step 1234, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:17.574445 #train# step 1235, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:18.905650 #train# step 1236, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:20.218309 #train# step 1237, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:21.529839 #train# step 1238, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:22.862493 #train# step 1239, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:24.185570 #train# step 1240, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:25.503156 #train# step 1241, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:26.835624 #train# step 1242, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:28.197414 #train# step 1243, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:29.560055 #train# step 1244, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:30.898585 #train# step 1245, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:32.288318 #train# step 1246, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:43:33.673938 #train# step 1247, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:35.068724 #train# step 1248, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:36.416737 #train# step 1249, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:37.774223 #train# step 1250, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:39.181987 #train# step 1251, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:43:40.559127 #train# step 1252, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:41.991682 #train# step 1253, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:43:43.329866 #train# step 1254, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:44.673809 #train# step 1255, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:46.017270 #train# step 1256, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:47.351613 #train# step 1257, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:48.693696 #train# step 1258, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:50.053852 #train# step 1259, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:51.430224 #train# step 1260, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:52.803359 #train# step 1261, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:54.155744 #train# step 1262, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:55.521718 #train# step 1263, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:56.964251 #train# step 1264, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:43:58.314872 #train# step 1265, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:43:59.664254 #train# step 1266, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:01.009224 #train# step 1267, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:02.354718 #train# step 1268, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:03.703833 #train# step 1269, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:05.041164 #train# step 1270, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:06.392148 #train# step 1271, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:07.736383 #train# step 1272, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:09.088897 #train# step 1273, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:10.428068 #train# step 1274, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:11.775043 #train# step 1275, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:13.121364 #train# step 1276, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:14.472368 #train# step 1277, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:15.836044 #train# step 1278, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:17.203281 #train# step 1279, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:18.559621 #train# step 1280, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:19.908322 #train# step 1281, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:21.263092 #train# step 1282, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:22.635854 #train# step 1283, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:23.983284 #train# step 1284, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:25.329317 #train# step 1285, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:26.699787 #train# step 1286, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:28.094279 #train# step 1287, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:29.476389 #train# step 1288, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:30.822844 #train# step 1289, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:32.177464 #train# step 1290, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:33.539390 #train# step 1291, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:34.885502 #train# step 1292, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:36.218478 #train# step 1293, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:37.551554 #train# step 1294, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:38.888689 #train# step 1295, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:40.224649 #train# step 1296, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:41.568434 #train# step 1297, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:42.909424 #train# step 1298, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:44.261646 #train# step 1299, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:45.603354 #train# step 1300, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:46.945819 #train# step 1301, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:48.269748 #train# step 1302, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:49.608849 #train# step 1303, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:50.952185 #train# step 1304, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:52.297474 #train# step 1305, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:53.631750 #train# step 1306, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:54.975641 #train# step 1307, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:56.317877 #train# step 1308, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:57.659354 #train# step 1309, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:44:58.987194 #train# step 1310, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:00.331091 #train# step 1311, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:01.667973 #train# step 1312, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:03.007592 #train# step 1313, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:04.345338 #train# step 1314, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:05.689833 #train# step 1315, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:07.024551 #train# step 1316, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:08.352754 #train# step 1317, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:09.688470 #train# step 1318, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:11.027493 #train# step 1319, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:12.358289 #train# step 1320, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:13.700299 #train# step 1321, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:15.036632 #train# step 1322, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:16.347423 #train# step 1323, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:17.705007 #train# step 1324, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:19.056329 #train# step 1325, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:20.403242 #train# step 1326, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:21.762263 #train# step 1327, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:23.117449 #train# step 1328, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:24.467009 #train# step 1329, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:25.807294 #train# step 1330, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:27.150157 #train# step 1331, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:28.489439 #train# step 1332, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:29.841032 #train# step 1333, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:31.217401 #train# step 1334, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:32.563499 #train# step 1335, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:33.907718 #train# step 1336, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:35.285561 #train# step 1337, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:36.613381 #train# step 1338, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:38.018904 #train# step 1339, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:45:39.355933 #train# step 1340, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:40.721112 #train# step 1341, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:42.076845 #train# step 1342, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:43.420330 #train# step 1343, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:44.766898 #train# step 1344, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:46.118927 #train# step 1345, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:47.474304 #train# step 1346, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:48.836352 #train# step 1347, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:50.196342 #train# step 1348, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:51.537245 #train# step 1349, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:52.877478 #train# step 1350, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:54.219322 #train# step 1351, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:55.568441 #train# step 1352, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:56.901195 #train# step 1353, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:58.225179 #train# step 1354, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:45:59.560628 #train# step 1355, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:00.900568 #train# step 1356, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:02.243359 #train# step 1357, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:03.583775 #train# step 1358, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:04.916327 #train# step 1359, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:06.240310 #train# step 1360, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:07.583233 #train# step 1361, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:08.906987 #train# step 1362, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:10.248596 #train# step 1363, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:11.579549 #train# step 1364, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:12.918034 #train# step 1365, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:14.248214 #train# step 1366, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:15.604353 #train# step 1367, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:16.943364 #train# step 1368, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:18.284324 #train# step 1369, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:19.635978 #train# step 1370, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:20.978709 #train# step 1371, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:22.322529 #train# step 1372, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:23.662592 #train# step 1373, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:25.003432 #train# step 1374, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:26.350780 #train# step 1375, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:27.699996 #train# step 1376, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:29.049393 #train# step 1377, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:30.396200 #train# step 1378, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:31.743384 #train# step 1379, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:33.087567 #train# step 1380, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:34.426908 #train# step 1381, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:35.768447 #train# step 1382, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:37.107695 #train# step 1383, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:38.438997 #train# step 1384, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:39.782164 #train# step 1385, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:41.121783 #train# step 1386, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:42.450479 #train# step 1387, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:43.794783 #train# step 1388, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:45.155385 #train# step 1389, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:46.500774 #train# step 1390, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:47.852665 #train# step 1391, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:49.193873 #train# step 1392, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:50.547309 #train# step 1393, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:51.891207 #train# step 1394, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:53.251119 #train# step 1395, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:54.591509 #train# step 1396, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:55.942409 #train# step 1397, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:57.298490 #train# step 1398, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:46:58.649621 #train# step 1399, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:00.006829 #train# step 1400, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:01.347828 #train# step 1401, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:02.696934 #train# step 1402, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:04.038369 #train# step 1403, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:05.386729 #train# step 1404, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:06.731428 #train# step 1405, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:08.083479 #train# step 1406, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:09.439279 #train# step 1407, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:10.777462 #train# step 1408, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:12.141421 #train# step 1409, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:13.504511 #train# step 1410, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:14.875239 #train# step 1411, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:16.249574 #train# step 1412, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:17.618818 #train# step 1413, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:18.987215 #train# step 1414, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:20.354070 #train# step 1415, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:21.716901 #train# step 1416, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:23.093752 #train# step 1417, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:24.450910 #train# step 1418, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:25.870104 #train# step 1419, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:47:27.227756 #train# step 1420, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:28.615149 #train# step 1421, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:29.981656 #train# step 1422, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:31.359203 #train# step 1423, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:32.726932 #train# step 1424, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:34.102232 #train# step 1425, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:35.456172 #train# step 1426, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:36.814964 #train# step 1427, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:38.168734 #train# step 1428, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:39.538661 #train# step 1429, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:40.870328 #train# step 1430, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:42.224925 #train# step 1431, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:43.570263 #train# step 1432, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:44.932532 #train# step 1433, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:46.280768 #train# step 1434, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:47.638853 #train# step 1435, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:49.027463 #train# step 1436, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:47:50.372741 #train# step 1437, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:51.740728 #train# step 1438, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:53.088529 #train# step 1439, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:54.439019 #train# step 1440, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:55.794500 #train# step 1441, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:57.146326 #train# step 1442, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:58.499638 #train# step 1443, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:47:59.818010 #train# step 1444, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:01.166569 #train# step 1445, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:02.510023 #train# step 1446, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:03.852328 #train# step 1447, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:05.206388 #train# step 1448, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:06.552603 #train# step 1449, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:07.898368 #train# step 1450, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:09.244765 #train# step 1451, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:10.574231 #train# step 1452, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:11.923385 #train# step 1453, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:13.267788 #train# step 1454, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:14.622047 #train# step 1455, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:15.975624 #train# step 1456, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:17.327372 #train# step 1457, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:18.666451 #train# step 1458, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:20.011728 #train# step 1459, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:21.348942 #train# step 1460, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:22.701500 #train# step 1461, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:24.048781 #train# step 1462, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:25.393888 #train# step 1463, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:26.744535 #train# step 1464, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:28.098989 #train# step 1465, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:29.449425 #train# step 1466, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:30.816766 #train# step 1467, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:32.177129 #train# step 1468, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:33.523734 #train# step 1469, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:34.868554 #train# step 1470, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:36.221312 #train# step 1471, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:37.575134 #train# step 1472, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:38.920112 #train# step 1473, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:40.266915 #train# step 1474, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:41.623535 #train# step 1475, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:42.984376 #train# step 1476, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:44.342599 #train# step 1477, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:45.691630 #train# step 1478, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:47.057835 #train# step 1479, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:48.401703 #train# step 1480, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:49.758046 #train# step 1481, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:51.094361 #train# step 1482, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:52.450067 #train# step 1483, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:53.766488 #train# step 1484, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:55.122334 #train# step 1485, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:56.466282 #train# step 1486, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:57.821825 #train# step 1487, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:48:59.175393 #train# step 1488, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:00.527022 #train# step 1489, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:01.876284 #train# step 1490, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:03.229612 #train# step 1491, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:04.584788 #train# step 1492, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:05.939689 #train# step 1493, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:07.279344 #train# step 1494, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:08.634009 #train# step 1495, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:09.985184 #train# step 1496, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:11.346355 #train# step 1497, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:12.691754 #train# step 1498, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:14.032103 #train# step 1499, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:15.385282 #train# step 1500, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:16.741311 #train# step 1501, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:18.091777 #train# step 1502, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:19.446910 #train# step 1503, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:20.803345 #train# step 1504, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:22.156785 #train# step 1505, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:23.535846 #train# step 1506, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:24.900601 #train# step 1507, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:26.265701 #train# step 1508, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:27.624160 #train# step 1509, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:28.954454 #train# step 1510, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:30.326871 #train# step 1511, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:31.680379 #train# step 1512, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:33.042702 #train# step 1513, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:34.404453 #train# step 1514, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:35.772222 #train# step 1515, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:37.146127 #train# step 1516, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:38.508211 #train# step 1517, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:39.865332 #train# step 1518, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:41.216050 #train# step 1519, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:42.582629 #train# step 1520, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:43.949796 #train# step 1521, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:45.293869 #train# step 1522, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:46.710903 #train# step 1523, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:49:48.075542 #train# step 1524, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:49.452796 #train# step 1525, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:50.811601 #train# step 1526, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:52.184291 #train# step 1527, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:53.551366 #train# step 1528, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:54.922170 #train# step 1529, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:56.272823 #train# step 1530, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:57.668529 #train# step 1531, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:49:59.034274 #train# step 1532, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:00.427913 #train# step 1533, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:01.786334 #train# step 1534, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:03.183499 #train# step 1535, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:04.585654 #train# step 1536, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:50:05.954364 #train# step 1537, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:07.310249 #train# step 1538, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:08.687678 #train# step 1539, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:10.042851 #train# step 1540, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:11.407022 #train# step 1541, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:12.757848 #train# step 1542, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:14.123310 #train# step 1543, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:15.482354 #train# step 1544, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:16.831820 #train# step 1545, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:18.171472 #train# step 1546, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:19.532819 #train# step 1547, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:20.872718 #train# step 1548, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:22.233751 #train# step 1549, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:23.595111 #train# step 1550, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:24.942716 #train# step 1551, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:26.290237 #train# step 1552, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:27.652519 #train# step 1553, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:29.014986 #train# step 1554, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:30.384313 #train# step 1555, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:31.749978 #train# step 1556, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:33.130779 #train# step 1557, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:34.498099 #train# step 1558, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:35.876511 #train# step 1559, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:37.213420 #train# step 1560, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:38.558796 #train# step 1561, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:39.909838 #train# step 1562, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:41.270822 #train# step 1563, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:42.629962 #train# step 1564, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:43.995781 #train# step 1565, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:45.359568 #train# step 1566, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:46.715067 #train# step 1567, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:48.079566 #train# step 1568, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:49.449563 #train# step 1569, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:50.813329 #train# step 1570, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:52.183869 #train# step 1571, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:53.541501 #train# step 1572, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:54.908115 #train# step 1573, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:56.263498 #train# step 1574, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:57.615160 #train# step 1575, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:50:58.974308 #train# step 1576, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:00.321954 #train# step 1577, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:01.679470 #train# step 1578, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:03.048421 #train# step 1579, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:04.427002 #train# step 1580, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:05.801781 #train# step 1581, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:07.160701 #train# step 1582, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:08.543469 #train# step 1583, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:09.909079 #train# step 1584, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:11.322664 #train# step 1585, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:12.719610 #train# step 1586, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:14.150153 #train# step 1587, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:15.597385 #train# step 1588, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:16.990324 #train# step 1589, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:18.379349 #train# step 1590, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:19.781982 #train# step 1591, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:21.221807 #train# step 1592, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:22.639615 #train# step 1593, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:24.100362 #train# step 1594, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:25.456871 #train# step 1595, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:26.837377 #train# step 1596, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:28.215622 #train# step 1597, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:29.598207 #train# step 1598, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:30.988555 #train# step 1599, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:32.377141 #train# step 1600, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:33.768226 #train# step 1601, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:35.167747 #train# step 1602, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:36.640817 #train# step 1603, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:38.014909 #train# step 1604, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:39.400710 #train# step 1605, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:40.770380 #train# step 1606, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:42.151395 #train# step 1607, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:43.535383 #train# step 1608, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:44.924924 #train# step 1609, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:46.298421 #train# step 1610, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:47.683237 #train# step 1611, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:49.065640 #train# step 1612, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:50.469021 #train# step 1613, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:51:51.870224 #train# step 1614, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:53.265400 #train# step 1615, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:54.593350 #train# step 1616, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:55.974138 #train# step 1617, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:57.355833 #train# step 1618, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:51:58.756366 #train# step 1619, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:00.205676 #train# step 1620, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:52:01.607283 #train# step 1621, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:52:02.981103 #train# step 1622, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:04.363818 #train# step 1623, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:05.731188 #train# step 1624, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:07.097041 #train# step 1625, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:08.464657 #train# step 1626, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:09.834723 #train# step 1627, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:11.187877 #train# step 1628, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:12.574605 #train# step 1629, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:13.940829 #train# step 1630, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:15.322268 #train# step 1631, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:16.694422 #train# step 1632, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:18.077330 #train# step 1633, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:19.452240 #train# step 1634, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:20.814175 #train# step 1635, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:22.179399 #train# step 1636, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:23.546615 #train# step 1637, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:24.907704 #train# step 1638, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:26.281400 #train# step 1639, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:27.655701 #train# step 1640, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:29.054212 #train# step 1641, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:52:30.423146 #train# step 1642, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:31.797384 #train# step 1643, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:33.170506 #train# step 1644, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:34.532364 #train# step 1645, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:35.887977 #train# step 1646, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:37.257227 #train# step 1647, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:38.627508 #train# step 1648, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:40.005729 #train# step 1649, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:41.376000 #train# step 1650, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:42.803048 #train# step 1651, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:52:44.175761 #train# step 1652, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:45.540063 #train# step 1653, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:46.921800 #train# step 1654, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:48.291834 #train# step 1655, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:49.678286 #train# step 1656, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:51.065114 #train# step 1657, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:52.433811 #train# step 1658, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:53.809135 #train# step 1659, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:55.226526 #train# step 1660, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:52:56.596690 #train# step 1661, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:57.963957 #train# step 1662, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:52:59.334625 #train# step 1663, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:00.722083 #train# step 1664, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:02.095597 #train# step 1665, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:03.480700 #train# step 1666, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:04.855124 #train# step 1667, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:06.239967 #train# step 1668, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:07.615107 #train# step 1669, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:08.988527 #train# step 1670, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:10.343816 #train# step 1671, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:11.718727 #train# step 1672, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:13.082392 #train# step 1673, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:14.438277 #train# step 1674, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:15.804946 #train# step 1675, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:17.164884 #train# step 1676, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:18.535164 #train# step 1677, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:19.898774 #train# step 1678, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:21.263650 #train# step 1679, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:22.630220 #train# step 1680, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:24.008562 #train# step 1681, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:25.391881 #train# step 1682, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:26.772511 #train# step 1683, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:28.152532 #train# step 1684, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:29.514797 #train# step 1685, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:30.870333 #train# step 1686, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:32.230825 #train# step 1687, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:33.576815 #train# step 1688, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:34.956782 #train# step 1689, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:36.321242 #train# step 1690, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:37.687902 #train# step 1691, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:39.055291 #train# step 1692, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:40.410334 #train# step 1693, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:41.786156 #train# step 1694, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:43.129608 #train# step 1695, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:44.502443 #train# step 1696, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:45.866883 #train# step 1697, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:47.232395 #train# step 1698, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:48.592183 #train# step 1699, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:49.968780 #train# step 1700, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:51.349002 #train# step 1701, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:52.711490 #train# step 1702, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:54.087014 #train# step 1703, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:55.451443 #train# step 1704, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:56.839423 #train# step 1705, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:58.208403 #train# step 1706, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:53:59.601625 #train# step 1707, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:00.980177 #train# step 1708, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:02.361915 #train# step 1709, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:03.739415 #train# step 1710, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:05.115359 #train# step 1711, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:06.505778 #train# step 1712, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:07.896561 #train# step 1713, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:09.284933 #train# step 1714, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:10.687850 #train# step 1715, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:54:12.074462 #train# step 1716, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:13.458052 #train# step 1717, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:14.853573 #train# step 1718, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:16.207043 #train# step 1719, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:17.567532 #train# step 1720, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:18.943673 #train# step 1721, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:20.325080 #train# step 1722, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:21.710317 #train# step 1723, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:23.103812 #train# step 1724, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:24.467276 #train# step 1725, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:25.833059 #train# step 1726, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:27.211870 #train# step 1727, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:28.571379 #train# step 1728, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:29.943112 #train# step 1729, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:31.316399 #train# step 1730, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:32.680663 #train# step 1731, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:34.046440 #train# step 1732, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:35.402191 #train# step 1733, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:36.772074 #train# step 1734, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:38.149787 #train# step 1735, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:39.517101 #train# step 1736, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:40.887838 #train# step 1737, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:42.256592 #train# step 1738, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:43.627726 #train# step 1739, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:44.999741 #train# step 1740, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:46.378619 #train# step 1741, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:47.710020 #train# step 1742, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:49.091500 #train# step 1743, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:50.464378 #train# step 1744, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:51.845592 #train# step 1745, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:53.226440 #train# step 1746, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:54.611941 #train# step 1747, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:55.983801 #train# step 1748, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:57.366285 #train# step 1749, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:54:58.736118 #train# step 1750, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:00.111866 #train# step 1751, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:01.486638 #train# step 1752, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:02.861154 #train# step 1753, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:04.229617 #train# step 1754, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:05.610079 #train# step 1755, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:06.978048 #train# step 1756, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:08.357051 #train# step 1757, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:09.728720 #train# step 1758, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:11.110049 #train# step 1759, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:12.477828 #train# step 1760, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:13.853682 #train# step 1761, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:15.225241 #train# step 1762, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:16.606244 #train# step 1763, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:17.979839 #train# step 1764, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:19.353318 #train# step 1765, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:20.725374 #train# step 1766, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:22.104061 #train# step 1767, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:23.468290 #train# step 1768, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:24.851912 #train# step 1769, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:26.237231 #train# step 1770, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:27.617066 #train# step 1771, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:28.992247 #train# step 1772, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:30.369066 #train# step 1773, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:31.735883 #train# step 1774, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:33.091742 #train# step 1775, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:34.477715 #train# step 1776, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:35.853997 #train# step 1777, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:37.231529 #train# step 1778, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:38.607984 #train# step 1779, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:39.985704 #train# step 1780, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:41.368671 #train# step 1781, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:42.751834 #train# step 1782, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:44.150619 #train# step 1783, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:45.545926 #train# step 1784, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:46.939962 #train# step 1785, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:48.302942 #train# step 1786, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:49.711217 #train# step 1787, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:51.079289 #train# step 1788, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:52.472459 #train# step 1789, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:53.831244 #train# step 1790, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:55.225993 #train# step 1791, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:55:56.590239 #train# step 1792, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:57.976750 #train# step 1793, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:55:59.356716 #train# step 1794, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:00.734703 #train# step 1795, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:02.118307 #train# step 1796, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:03.504879 #train# step 1797, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:04.887407 #train# step 1798, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:06.271316 #train# step 1799, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:07.688445 #train# step 1800, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:09.069571 #train# step 1801, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:10.472698 #train# step 1802, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:11.861769 #train# step 1803, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:13.255189 #train# step 1804, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:14.663655 #train# step 1805, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:16.044179 #train# step 1806, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:17.432787 #train# step 1807, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:18.839619 #train# step 1808, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:20.224392 #train# step 1809, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:21.614090 #train# step 1810, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:22.977646 #train# step 1811, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:24.378326 #train# step 1812, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:25.784147 #train# step 1813, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:27.234527 #train# step 1814, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:28.631702 #train# step 1815, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:30.019440 #train# step 1816, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:31.464435 #train# step 1817, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:32.928919 #train# step 1818, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:34.452453 #train# step 1819, loss = nan, cross_entropy loss = inf, 1.5 sec/batch
2019-05-04 21:56:35.843101 #train# step 1820, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:37.222750 #train# step 1821, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:38.603185 #train# step 1822, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:39.993174 #train# step 1823, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:41.407118 #train# step 1824, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:42.812907 #train# step 1825, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:44.203114 #train# step 1826, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:45.596399 #train# step 1827, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:47.083226 #train# step 1828, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:48.488134 #train# step 1829, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:49.887209 #train# step 1830, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:51.281597 #train# step 1831, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:52.667157 #train# step 1832, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:54.064943 #train# step 1833, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:55.457979 #train# step 1834, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:56.858844 #train# step 1835, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:56:58.279627 #train# step 1836, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:56:59.710479 #train# step 1837, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:01.142585 #train# step 1838, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:02.540099 #train# step 1839, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:03.933394 #train# step 1840, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:05.364753 #train# step 1841, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:06.715651 #train# step 1842, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:08.111431 #train# step 1843, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:09.502366 #train# step 1844, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:10.934484 #train# step 1845, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:12.319380 #train# step 1846, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:13.706942 #train# step 1847, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:15.088156 #train# step 1848, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:16.486347 #train# step 1849, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:17.870220 #train# step 1850, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:19.254065 #train# step 1851, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:20.639360 #train# step 1852, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:22.032885 #train# step 1853, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:23.419900 #train# step 1854, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:24.808346 #train# step 1855, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:26.187002 #train# step 1856, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:27.534036 #train# step 1857, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:28.928763 #train# step 1858, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:30.327647 #train# step 1859, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:31.699208 #train# step 1860, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:33.091982 #train# step 1861, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:34.463236 #train# step 1862, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:35.842681 #train# step 1863, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:37.247899 #train# step 1864, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:38.640749 #train# step 1865, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:40.023525 #train# step 1866, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:41.418039 #train# step 1867, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:42.807785 #train# step 1868, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:44.185498 #train# step 1869, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:45.565033 #train# step 1870, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:46.946551 #train# step 1871, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:48.332089 #train# step 1872, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:49.708902 #train# step 1873, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:51.106566 #train# step 1874, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:52.515311 #train# step 1875, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:53.905612 #train# step 1876, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:55.304123 #train# step 1877, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:56.744069 #train# step 1878, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:57:58.127471 #train# step 1879, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:57:59.556483 #train# step 1880, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:00.962990 #train# step 1881, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:02.364226 #train# step 1882, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:03.760626 #train# step 1883, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:05.162167 #train# step 1884, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:06.563514 #train# step 1885, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:07.958001 #train# step 1886, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:09.352170 #train# step 1887, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:10.736282 #train# step 1888, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:12.118748 #train# step 1889, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:13.504979 #train# step 1890, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:14.898373 #train# step 1891, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:16.292433 #train# step 1892, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:17.659158 #train# step 1893, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:19.018700 #train# step 1894, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:20.411360 #train# step 1895, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:21.792831 #train# step 1896, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:23.176807 #train# step 1897, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:24.544840 #train# step 1898, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:25.928229 #train# step 1899, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:27.312896 #train# step 1900, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:28.692660 #train# step 1901, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:30.071819 #train# step 1902, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:31.451668 #train# step 1903, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:32.829117 #train# step 1904, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:34.210676 #train# step 1905, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:35.578102 #train# step 1906, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:36.956591 #train# step 1907, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:38.330615 #train# step 1908, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:39.705256 #train# step 1909, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:41.090993 #train# step 1910, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:42.475363 #train# step 1911, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:43.862320 #train# step 1912, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:45.214878 #train# step 1913, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:46.600070 #train# step 1914, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:47.976432 #train# step 1915, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:49.354722 #train# step 1916, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:50.733687 #train# step 1917, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:52.111768 #train# step 1918, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:53.486534 #train# step 1919, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:54.872822 #train# step 1920, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:56.262087 #train# step 1921, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:58:57.642096 #train# step 1922, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:58:59.036384 #train# step 1923, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:00.433081 #train# step 1924, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:01.814683 #train# step 1925, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:03.206185 #train# step 1926, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:04.587652 #train# step 1927, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:05.972607 #train# step 1928, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:07.351852 #train# step 1929, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:08.745381 #train# step 1930, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:10.100154 #train# step 1931, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:11.480503 #train# step 1932, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:12.870560 #train# step 1933, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:14.250313 #train# step 1934, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:15.637135 #train# step 1935, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:17.026276 #train# step 1936, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:18.408539 #train# step 1937, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:19.801607 #train# step 1938, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:21.186855 #train# step 1939, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:22.577556 #train# step 1940, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:23.971320 #train# step 1941, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:25.383805 #train# step 1942, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:26.773949 #train# step 1943, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:28.149064 #train# step 1944, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:29.546315 #train# step 1945, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:30.946862 #train# step 1946, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:32.367944 #train# step 1947, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:33.759107 #train# step 1948, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:35.168300 #train# step 1949, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:36.602023 #train# step 1950, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:38.003051 #train# step 1951, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:39.431998 #train# step 1952, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:40.805695 #train# step 1953, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:42.204267 #train# step 1954, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:43.605861 #train# step 1955, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:45.005564 #train# step 1956, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:46.396632 #train# step 1957, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:47.781263 #train# step 1958, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:49.171312 #train# step 1959, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:50.560979 #train# step 1960, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:51.936264 #train# step 1961, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:53.318415 #train# step 1962, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:54.701870 #train# step 1963, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:56.095057 #train# step 1964, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 21:59:57.468429 #train# step 1965, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 21:59:58.858968 #train# step 1966, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:00.239242 #train# step 1967, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:01.615295 #train# step 1968, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:03.007504 #train# step 1969, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:04.395331 #train# step 1970, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:05.771030 #train# step 1971, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:07.139872 #train# step 1972, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:08.529706 #train# step 1973, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:09.922071 #train# step 1974, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:11.317873 #train# step 1975, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:12.717155 #train# step 1976, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:14.120394 #train# step 1977, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:15.508534 #train# step 1978, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:16.896681 #train# step 1979, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:18.278148 #train# step 1980, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:19.656441 #train# step 1981, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:21.028099 #train# step 1982, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:22.417110 #train# step 1983, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:23.807436 #train# step 1984, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:25.187421 #train# step 1985, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:26.568142 #train# step 1986, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:27.956667 #train# step 1987, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:29.330354 #train# step 1988, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:30.714476 #train# step 1989, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:32.092516 #train# step 1990, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:33.466535 #train# step 1991, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:34.858672 #train# step 1992, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:36.248049 #train# step 1993, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:37.628025 #train# step 1994, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:38.995556 #train# step 1995, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:40.378880 #train# step 1996, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:41.756843 #train# step 1997, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:43.143015 #train# step 1998, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:44.518855 #train# step 1999, loss = nan, cross_entropy loss = inf, 1.3 sec/batch
2019-05-04 22:00:45.909610 #train# step 2000, loss = nan, cross_entropy loss = inf, 1.4 sec/batch
2019-05-04 22:00:45.909678 #traing# finish training
saving model to ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_cifar10.npy
model saved
initializing
launching session
loading img model from ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_cifar10.npy
['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc6', 'fc7', 'fc8']
img model loading finished
Initializing Dataset
Dataset already
Initializing Dataset
Dataset already
2019-05-04 22:01:21.306559 #validation# start validation
2019-05-04 22:01:21.306611 #validation# totally 1000 query in 10 batches
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
Cosine Loss: inf
2019-05-04 22:01:30.785122 #validation# totally 54000 database in 540 batches
Cosine Loss[0/540]: inf
Cosine Loss[100/540]: inf
Cosine Loss[200/540]: inf
Cosine Loss[300/540]: inf
Cosine Loss[400/540]: inf
Cosine Loss[500/540]: inf
/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/DeepHash/evaluation/__init__.py:108: RuntimeWarning: invalid value encountered in less_equal
  idx = np.reshape(np.argwhere(ips[i, :] <= radius), (-1))
i2i_by_feature: 0.10021170032299656
i2i_after_sign: 0.10021170032299656
i2i_prec_radius_2: 0.0
i2i_recall_radius_2: 0.0
i2i_map_radius_2: 0.0
{'R': 54000,
 'alpha': 10.0,
 'batch_size': 256,
 'cq_lambda': 0.0,
 'dataset': 'cifar10',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/database.txt',
 'img_model': 'alexnet',
 'img_te': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/test.txt',
 'img_tr': '/home/chenshen/Projects/Hash/DeepHash/CY-DeepHash/data/cifar10/train.txt',
 'label_dim': 10,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'cross_entropy',
 'max_iter': 2000,
 'model_weights': './models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_cifar10.npy',
 'output_dim': 32,
 'save_dir': './models/',
 'val_batch_size': 100}
